<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Categories on Max Fierro</title>
    <link>http://localhost:1313/categories/</link>
    <description>Recent content in Categories on Max Fierro</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    
	<atom:link href="http://localhost:1313/categories/index.xml" rel="self" type="application/rss+xml" />
    
    
    
    
    
    
    
    <item>
      <title>Poem 2. &#34;Occidental&#34;</title>
      <link>http://localhost:1313/poem-2.-occidental/</link>
      <pubDate>Wed, 30 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/poem-2.-occidental/</guid>
      <description>&lt;p&gt;El negro de la noche es el final del infinito;&lt;br&gt;
la verdad me llega a la velocidad de la luz.&lt;br&gt;
Son trayectorias que trazan entre los átomos,&lt;br&gt;
son curvas que desnudan misterios paralelos.&lt;br&gt;
Es hipótesis de tiempo escrita en el espacio,&lt;br&gt;
es información que se filtra entre la materia.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>The Elo Rating System through Likelihood Gradient Ascent</title>
      <link>http://localhost:1313/the-elo-rating-system-through-likelihood-gradient-ascent/</link>
      <pubDate>Wed, 30 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/the-elo-rating-system-through-likelihood-gradient-ascent/</guid>
      <description>&lt;aside id=&#34;toc&#34;&gt;
    &lt;details&gt;
        &lt;summary&gt;&amp;nbsp;&lt;strong&gt; Table of contents&lt;/strong&gt;&lt;/summary&gt;
        &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#background&#34;&gt;Background&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#mathematical-orderings&#34;&gt;Mathematical Orderings&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#elo-ratings-and-updates&#34;&gt;Elo Ratings and Updates&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#maximum-likelihood-estimation&#34;&gt;Maximum Likelihood Estimation&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#derivation&#34;&gt;Derivation&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#map-estimation-1&#34;&gt;MAP Estimation&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#discussion&#34;&gt;Discussion&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#gaussian-convolution&#34;&gt;Gaussian Convolution&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
    &lt;/details&gt;
&lt;/aside&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Probability and optimization are strong monsters. The &lt;a href=&#34;https://en.wikipedia.org/wiki/Elo_rating_system&#34;&gt;Elo rating system&lt;/a&gt;, used to estimate performance in &lt;a href=&#34;https://en.wikipedia.org/wiki/FIDE_rankings&#34;&gt;competitive chess&lt;/a&gt;, &lt;a href=&#34;https://www.vox.com/2019/2/7/18210998/tinder-algorithm-swiping-tips-dating-app-science&#34;&gt;online dating&lt;/a&gt;, and &lt;a href=&#34;https://lmsys.org/blog/2023-05-03-arena/&#34;&gt;AI agents&lt;/a&gt;, is an under-the-hood reminder of this fact that operates within many of the systems that need to establish comparative metrics. This piece is my contribution to the endless pile of explainers on the topic. I exercise an emphasis on bayesian statistics and optimization that should ring a bell for anyone familiar with the basics of machine learning.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h3 id=&#34;mathematical-orderings&#34;&gt;Mathematical Orderings&lt;/h3&gt;
&lt;p&gt;At the risk of including a needless dependency on the topic of this piece, I introduce you to the idea of an ordering.
Colloquially, we take this to mean an arrangement (i.e., &lt;a href=&#34;https://en.wikipedia.org/wiki/Permutation&#34;&gt;a permutation&lt;/a&gt;) of a set of things.
We will replace that with its formal meaning, which is a specific kind of &lt;a href=&#34;https://en.wikipedia.org/wiki/Binary_relation&#34;&gt;binary relation&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Definition&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;A &lt;strong&gt;binary relation&lt;/strong&gt; $R$ from a set $X$ to another $Y$ is a subset of $X \times Y$, where it is possible that $X = Y$.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This should seem odd, as a subset is in no obvious way reminiscent of a permutation. But introducing some new syntax to indicate membership in a relation,&lt;/p&gt;
$$
  (x, y) \in R \vdash xRy,
$$&lt;p&gt;we are an example away from making sense. In particular, consider $R = \, \leq$ (less-than). When we say things like &amp;ldquo;$x \leq y$,&amp;rdquo; we are in fact using syntactic sugar for &amp;ldquo;$(x, y) \in \, \leq$.&amp;rdquo; With this in mind, we can take a look at &lt;a href=&#34;https://en.wikipedia.org/wiki/Partially_ordered_set&#34;&gt;partial orders&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Definition&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;A &lt;strong&gt;partial order&lt;/strong&gt; $R$ is a binary relation over a set $X$ and itself which satisfies the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Reflexivity. This means that $\forall x \in X, \, xRx$.&lt;/li&gt;
&lt;li&gt;Antisymmetry. This means that $\forall (x, y) \in X^2, \, xRy \wedge yRx \implies x = y$.&lt;/li&gt;
&lt;li&gt;Transitivity. This means that $\forall (x, y, z) \in X^3, \, xRy \wedge yRz \implies xRz$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The canonical example of a partial order is $\subseteq$ over $\mathcal P(S)$. Importantly, a partial order over a set does not imply a permutation over it, because of the possibility for two elements $x$ and $y$ to be &lt;em&gt;unrelated&lt;/em&gt;, or in other words, for $\neg xRy$ and $\neg yRx$. In a &lt;a href=&#34;https://en.wikipedia.org/wiki/Total_order&#34;&gt;total order&lt;/a&gt;, we simply do not allow this.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Definition&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;A &lt;strong&gt;total order&lt;/strong&gt; $R$ is a partial order that is also total, which means that $\forall (x, y) \in X^2, \, xRy \vee yRx$.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The canonical example of a total order is $\leq$ over $\mathbb{R}$. With a total order, there is a single valid ordering $\bold{x}$ (i.e. arrangement or permutation) over its set $X$ such that $x_iRx_{i + 1}$ for all $i = 0, \ldots, |X| - 1$. One more variation we can make on the idea of an order is that of a &lt;a href=&#34;https://en.wikipedia.org/wiki/Weak_ordering&#34;&gt;weak order&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Definition&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;A &lt;strong&gt;weak order&lt;/strong&gt; $R$ is a total order that is not necessarily antisymmetric.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In other words, it is possible that for distinct elements $x$ and $y$, both $xRy$ and $yRx$. This is conceptually aligned with allowing &amp;ldquo;ties&amp;rdquo; in any resulting ordering, potentially sacrificing their uniqueness.&lt;/p&gt;
&lt;h3 id=&#34;elo-ratings-and-updates&#34;&gt;Elo Ratings and Updates&lt;/h3&gt;
&lt;p&gt;We can take a look at the question that &lt;a href=&#34;https://en.wikipedia.org/wiki/Arpad_Elo&#34;&gt;Arpad Elo&lt;/a&gt; (kind of) answered: How can you compare the skill level of two chess players?&lt;/p&gt;
&lt;style&gt;
    .halign-container {
        display: flex;
        width: 100%;
        justify-content: center;  
    }
&lt;/style&gt;
&lt;div class=&#34;halign-container&#34;&gt;
&lt;figure&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;arpad_elo.jpg&#34;
         alt=&#34;Arpad Elo (August 25, 1903 – November 5, 1992)&#34; width=&#34;256&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Arpad Elo (August 25, 1903 – November 5, 1992)&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;/div&gt;

&lt;p&gt;His proposed procedure is straightforward. Each player $i \in N$ will have a real-valued rating $r_i$, which will be a proxy for their skill level. These ratings will be initialized at some predetermined value for all players. Then, when there is a match between player $i$ and $j$, the following updates are made:&lt;/p&gt;
$$
\begin{align*}
&amp;r_j \gets r_j + k(s_j - e_j), \\
&amp;r_i \gets r_i + k(s_i - e_i),
\end{align*}
$$&lt;p&gt;where&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;,&lt;/p&gt;
$$
e_p = \frac{1}{1 + e^{-(r_p - r_{\text{other}})}}, \;\;\;\;
s_p = 
\begin{cases}
1 &amp;\text{if \(p\) wins},\\
0.5 &amp;\text{if draw},\\
0 &amp;\text{if \(p\) loses},\\
\end{cases}
$$&lt;p&gt;and $k$ is a constant chosen arbitrarily. So, as players accrue matches with other players, their ratings are updated according to the above rules with the hope that they will eventually stabilize. Now, the difference between players&amp;rsquo; ratings can be used to compare their skill levels via the ordering $\leq$ on $\mathbb{R}$.&lt;/p&gt;
&lt;h3 id=&#34;maximum-likelihood-estimation&#34;&gt;Maximum Likelihood Estimation&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&#34;&gt;Maximum likelihood estimation (MLE)&lt;/a&gt; is a method used to fit distribution parameters to samples. The setup for MLE is a random variable $Y$ of known distribution $\mathcal{D_\theta}$ (parameterized by $\theta$), with access to &lt;a href=&#34;https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables&#34;&gt;IID&lt;/a&gt; samples $\langle y_i \rangle \sim \mathcal{D}_\theta$. The objective is to estimate $\hat\theta$ such that the &lt;a href=&#34;https://en.wikipedia.org/wiki/Likelihood_function&#34;&gt;likelihood function&lt;/a&gt; $\mathcal{L}$ is maximized,&lt;/p&gt;
$$
\begin{equation}
    \hat\theta_\mathrm{MLE} 
    = \argmax_\theta \, \mathcal{L}(\theta; \langle y_i \rangle) 
    = \argmax_\theta \, \prod_i \mathbb{P}_\theta[Y = y_i].
\end{equation}
$$&lt;p&gt;In other words, MLE is the optimization procedure associated with finding the distribution parameters that were most likely to generate observed data, provided that we know or assume its distribution.&lt;/p&gt;
&lt;h4 id=&#34;map-estimation&#34;&gt;MAP Estimation&lt;/h4&gt;
&lt;p&gt;When there is access to a (known or assumed) prior $p(\theta)$ on the distribution of parameters, we can fold it into our optimization process by doing MLE on the posterior distribution, which by &lt;a href=&#34;https://en.wikipedia.org/wiki/Bayes%27_theorem&#34;&gt;Bayes&amp;rsquo; theorem&lt;/a&gt;,&lt;/p&gt;
$$
\begin{align*}
    p(\theta \mid \langle y_i\rangle) 
    &amp;= \frac{p(\langle y_i \rangle \mid \theta) p(\theta)}{p(\langle y_i \rangle)} 
    \; \propto \; \underbrace{p(\langle y_i \rangle \mid \theta)}_{\displaystyle{\mathcal{L}(\theta; \langle y_i \rangle)}} p(\theta).
\end{align*}
$$&lt;p&gt;The resulting parameters $\hat\theta_\mathrm{MAP}$ are then a &lt;a href=&#34;https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation&#34;&gt;maximum a posteriori (MAP)&lt;/a&gt; estimate,&lt;/p&gt;
$$
\begin{align*}
    \hat\theta_{\mathrm{MAP}}
    &amp;= \argmax_\theta\;p\bigl(\theta \mid \langle y_i\rangle\bigr) \\
    &amp;= \argmax_\theta\;\Bigl[\mathcal{L}\bigl(\theta;\langle y_i\rangle\bigr)\,p(\theta)\Bigr] \\
    &amp;= \argmax_\theta\;\Bigl[\prod_{i=1}^n \mathbb{P}_\theta\bigl[Y=y_i\bigr] \times p(\theta)\Bigr].
\end{align*}
$$&lt;h4 id=&#34;optimization&#34;&gt;Optimization&lt;/h4&gt;
&lt;p&gt;Sometimes, it is possible to find closed-form solutions for $\hat\theta_\mathrm{MAP}$ and $\hat\theta_\mathrm{MLE}$ through convex optimization. For example, samples with gaussian noise lead to the closed-form solution of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Ordinary_least_squares&#34;&gt;OLS problem&lt;/a&gt; through the process of MLE.&lt;/p&gt;
&lt;p&gt;However, most of the time the resulting optimization objective of MLE (and hence also MAP estimation) is not convex. Here, gradient-based approaches (along with all other non-convex optimization techniques) are helpful for finding local maxima of the likelihood objective.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;derivation&#34;&gt;Derivation&lt;/h2&gt;
&lt;p&gt;The derivation presented here will depart from the usual in hopes of contributing some kind of novelty. We begin with the game-theory-native idea of payoff, which we will take to be a numeric value representing a player&amp;rsquo;s utility differential with respect to the start of a game $G$,&lt;/p&gt;
$$
    \text{payoff of player i} = p_i.
$$&lt;p&gt;Next, we will consider player performance. Just as Elo, we take the performance of a player $i$ on a game $G$ to be a real-valued random variable $X_i$, independent to other players.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Observation&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;Perhaps Elo motivated this decision after noticing the variance of his own performance over the chess board.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Then, we will expand our setup by allowing players to outperform others, which we will present through the difference between the performance of two players during $G$ (which is another RV),&lt;/p&gt;
$$
    \delta_{i, \, j} = X_i - X_j.
$$&lt;p&gt;We will also establish a relationship between $\delta_{i , \, j}$ and $p_i$. For this purpose, we introduce a game-specific mapping $g$ with a noise term $\epsilon \sim \mathcal{N}(0, \sigma_\epsilon^2)$, which together form the generative process of payoffs:&lt;/p&gt;
$$
    p_i = g(\delta_{i, \, j}) + \epsilon.
$$&lt;p&gt;Finally, we will assert a prior on the distribution of $X_i$, which we will refer to as $\mathcal{D}(\theta_i)$ without yet deciding on a particular distribution (just that it is parameterized by $\theta_i$). This prior $\pi(x)$ will be global for all players, and its distribution parameters will be $\theta_\pi$.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Note&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;While this is a global prior, notice that none of the following breaks if it were player-specific from the start.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;So far, none of this has helped us answer the question that Elo answered. For that, we will introduce one last artifact on top of our setup; each player $i$ will have a &amp;ldquo;rating&amp;rdquo; $r_i$, which we will ultimately use to order players by skill in our system or organization:&lt;/p&gt;
$$
    r_i = \mathbb{E}[X_i].
$$&lt;h3 id=&#34;map-estimation-1&#34;&gt;MAP Estimation&lt;/h3&gt;
&lt;p&gt;Clearly, since our goal is to know players&amp;rsquo; ratings, the only additional information we will need to get them are the distribution parameters $\theta_i$. Of course, at a lack of observations, we can assert from our prior&lt;/p&gt;
$$
    r_i = \mathbb{E}_{X \, \sim \, \pi}[X].
$$&lt;p&gt;But what if at the end of a game $G$ between players $i$ and $j$, we observe &lt;a href=&#34;https://en.wikipedia.org/wiki/Without_loss_of_generality&#34;&gt;WLOG&lt;/a&gt; the payoff $p_i$? Here, we will be wishing that $g$ is neatly invertible. Assuming it is, we arrive at the following MLE for their difference in performance via application of $(1)$:&lt;/p&gt;
$$
\begin{equation}
    \hat\delta_{i, \, j}
    = \argmax_{\delta} \exp\!\Bigl(-\frac{(p_i-g(\delta))^2}{2\sigma_\epsilon^2}\Bigr)
    = g^{-1}(p_i).
\end{equation}
$$&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Note&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;Notice &lt;strong&gt;we did not use a prior&lt;/strong&gt; when estimating $\hat\delta_{i, \, j}$. This assumption is due to Elo; we will not use players&amp;rsquo; history when calculating their performance for a single game. This is the design decision that, by omission, accounts for sudden changes in player skill (as a result of learning, etc.).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Note&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;We just estimated the difference between the performance of the players from the payoff of a single player. The invertibility of $g$ has the hidden implication that &lt;strong&gt;it is strictly monotonic&lt;/strong&gt;; no two differences in performance lead to the same payoff, and the greater the difference, the greater the payoff for the outperforming player.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Knowing this, we can perform a bayesian update to our prior through MAP estimation. Writing down the joint posterior of the parameters of $X_i$ and $X_j$,&lt;/p&gt;
$$
\begin{equation}
    p(\theta_i, \, \theta_j  \mid \hat\delta_{i, \, j}) 
    \propto 
    \underbrace{
        p(\hat\delta_{i, \, j} \mid \theta_i, \, \theta_j)
    }_{
        \displaystyle{p(\hat\delta_{i, \, j} \mid X_i - X_j)}
    }
    p(\theta_i)p(\theta_j).
\end{equation}
$$&lt;p&gt;Notice that we already have access to priors $p(\theta_i)$ and $p(\theta_j)$; those are quite simply $\pi(\theta_i)$ and $\pi(\theta_j)$, which we assume per our initial setup.&lt;/p&gt;
&lt;h4 id=&#34;gaussian-performance&#34;&gt;Gaussian Performance&lt;/h4&gt;
&lt;p&gt;We proceed by considering the case where $X_i \sim \mathcal{N}(r_i, \, \sigma_i^2)$, such that $\theta_i = (r_i, \, \sigma_i^2)$. That is, player performance is gaussian-distributed,&lt;/p&gt;
$$
\begin{equation}
    p_{X_i}(x_i \mid \theta_i)
    = \frac{1}{\sqrt{2\pi} \, \sigma_i}
      \exp\!\Bigl(-\frac{(x_i - r_i)^2}{2\,\sigma_i^2}\Bigr).
\end{equation}
$$&lt;p&gt;Our next goal is to set up an analytic function for the likelihood $p(\hat\delta_{i, \, j} \mid \theta_i, \, \theta_j)$. We observe that we have access to the conditional density of $\hat\delta_{i, \, j}$&lt;/p&gt;
$$
\begin{equation}
    p(\hat\delta_{i, \, j} \mid x_i, \, x_j)
    = \frac{1}{\sqrt{2\pi}\,\sigma_\varepsilon}
      \exp\!\Bigl(-\frac{\bigl(g(\hat\delta_{i, \, j}) - (x_i - x_j)\bigr)^2}{2\,\sigma_\varepsilon^2}\Bigr)
      \;|g&#39;(\hat\delta_{i, \, j})|
\end{equation}
$$&lt;p&gt;by using $(2)$ implicitly through the change of variables&lt;/p&gt;
$$
    p(\hat\delta_{i, \, j} \mid x_i, \, x_j)
    = p_{p_i}\bigl(g(\hat\delta_{i, \, j}) \mid x_i, \, x_j \bigr)
    \;\Bigl|\frac{d}{d\hat\delta_{i, \, j}}\,g(\hat\delta_{i, \, j})\Bigr|,
$$&lt;p&gt;where we take&lt;/p&gt;
$$
    p\bigl(p_i \mid x_i, \, x_j \bigr)
    = \frac{1}{\sqrt{2\pi}\,\sigma_\varepsilon}
      \exp\!\Bigl(-\frac{\bigl(p_i - g(x_i - x_j)\bigr)^2}{2\,\sigma_\varepsilon^2}\Bigr).
$$&lt;p&gt;Now, we can use $(4)$ and $(5)$ to derive the desired likelihood by marginalizing,&lt;/p&gt;
$$
\begin{align*}
    p\bigl(\hat\delta_{i, \, j} \mid \theta_i,\theta_j\bigr)
    &amp;= \iint
       p\bigl(\hat\delta_{i, \, j}\mid x_i,x_j\bigr)\;
       p_{X_i}(x_i \mid \theta_i)\;p_{X_j}(x_j \mid \theta_j)\,
       dx_i\,dx_j \\
    &amp;= \iint
       \frac{1}{\sqrt{2\pi}\,\sigma_\varepsilon}
       \exp\!\Bigl(-\frac{\bigl(g(\hat\delta_{i, \, j}) - (x_i - x_j)\bigr)^2}
                         {2\,\sigma_\varepsilon^2}\Bigr)\,
       \bigl|g&#39;(\hat\delta_{i, \, j})\bigr|
    \\[-2pt]
    &amp;\quad\;\times\,
       \frac{1}{\sqrt{2\pi}\,\sigma_i}
       \exp\!\Bigl(-\frac{(x_i - r_i)^2}{2\,\sigma_i^2}\Bigr)
       \;\frac{1}{\sqrt{2\pi}\,\sigma_j}
       \exp\!\Bigl(-\frac{(x_j - r_j)^2}{2\,\sigma_j^2}\Bigr)
    \,dx_i\,dx_j.
    \\[6pt]
\end{align*}
$$&lt;p&gt;After another cup of coffee, we arrive at the following version of our joint likelihood $p\bigl(\hat\delta_{i, , j} \mid \theta_i,\theta_j\bigr)$,&lt;/p&gt;
$$
\begin{aligned}
    &amp;= \int
       \frac{1}{\sqrt{2\pi}\,\sigma_\varepsilon}
       \exp\!\Bigl(-\frac{\bigl(g(\hat\delta_{i, \, j}) - d\bigr)^2}{2\,\sigma_\varepsilon^2}\Bigr)
       \;|g&#39;(\hat\delta_{i, \, j})|\; \\
    &amp;\quad\;\quad\;\times \frac{1}{\sqrt{2\pi(\sigma_i^2+\sigma_j^2)}}
       \exp\!\Bigl(-\frac{(d - (r_i - r_j))^2}{2(\sigma_i^2+\sigma_j^2)}\Bigr)
    \,dd
\end{aligned}
$$&lt;p&gt;where $d = x_i - x_j$ (hinted at in equation $(3)$) is possible because $X_i - X_j \sim \mathcal{N}(r_i - r_j, \sigma_i^2 + \sigma_j^2)$. Finally, we obtain the following after remembering an &lt;a href=&#34;#gaussian-convolution&#34;&gt;important fact&lt;/a&gt; from signal processing,&lt;/p&gt;
$$
\begin{align}
    \mathcal{J}_\mathrm{MLE}(\theta_i, \, \theta_j; \, \hat\delta_{i, \, j})
    = \frac{|g&#39;(\hat\delta_{i, \, j})|}{\sqrt{2\pi\,\bigl(\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2\bigr)}}\,
        \exp\!\Biggl(-\frac{\bigl(g(\hat\delta_{i, \, j}) - (r_i - r_j)\bigr)^2}
                             {2\,\bigl(\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2\bigr)}\Biggr).
\end{align}
$$&lt;p&gt;Wonderful. We then attend to the reflexes drilled into our brains from machine learning, and find the gradient of the log-likelihood with respect to learned&amp;hellip; ahem, the ratings $\bold{r} = [r_i, \, r_j]^\top$:&lt;/p&gt;
$$
\begin{equation}
    \nabla_\bold{r}\log\mathcal{J}_\mathrm{MLE}(\theta_i, \, \theta_j; \, \hat\delta_{i, \, j}) = 
    \begin{bmatrix}
        \displaystyle\frac{g(\hat\delta_{i, \, j}) - (r_i - r_j)}{\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2} \\[8pt]
        \\
        \displaystyle-\frac{g(\hat\delta_{i, \, j}) - (r_i - r_j)}{\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2}
    \end{bmatrix}.
\end{equation}
$$&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Note&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;By taking the $\log$ of the joint likelihood we achieve nothing, but we respect a very important tradition&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Using $\nabla_\bold{r}\log\mathcal{J}(\theta_i, \, \theta_j; \, \hat\delta_{i, \, j})$ as it stands to adjust $\bold{r}$ would be tantamount to MLE on $\bold{r}$. To turn this into a proper MAP estimate we must also fold in our prior terms into $(6)$, which we assume to be gaussian:&lt;/p&gt;
$$
\begin{aligned}
    \mathcal{J}_\mathrm{MAP}(\theta_i, \, \theta_j; \, \hat\delta_{i, \, j})
    &amp;= \frac{\lvert g&#39;(\hat\delta_{i,j})\rvert}
           {\sqrt{2\pi\,\bigl(\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2\bigr)}}
      \exp\!\Bigl(-\frac{\bigl(g(\hat\delta_{i, \, j}) - (r_i - r_j)\bigr)^2}
                       {2\,\bigl(\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2\bigr)}\Bigr)\\
    &amp;\quad\;\times\;
      \frac{1}{\sqrt{2\pi}\,\sigma_\pi}
      \exp\!\Bigl(-\frac{(r_i - r_\pi)^2}{2\,\sigma_\pi^2}\Bigr)
      \;\times\;
      \frac{1}{\sqrt{2\pi}\,\sigma_\pi}
      \exp\!\Bigl(-\frac{(r_j - r_\pi)^2}{2\,\sigma_\pi^2}\Bigr).
\end{aligned}
$$&lt;p&gt;Being again unable to ignore our instincts,&lt;/p&gt;
$$
\begin{equation}
    \nabla_{\mathbf r}\log \mathcal{J}_{\mathrm{MAP}}(\theta_i,\theta_j;\hat\delta_{i, \, j})
    = \begin{bmatrix}
    \displaystyle
    \frac{g(\hat\delta_{i, \, j}) - (r_i - r_j)}{\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2}
    \\\\
    \displaystyle
    -\frac{g(\hat\delta_{i, \, j}) - (r_i - r_j)}{\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2}
    \end{bmatrix}
    -
    \begin{bmatrix}
    \displaystyle
\frac{r_i - r_\pi}{\sigma_\pi^2}
\\\\
    \displaystyle
\frac{r_j - r_\pi}{\sigma_\pi^2}
    \end{bmatrix}.
\end{equation}
$$&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Checkpoint&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;Let us take a step back for a second, and roughly see what is on the table. Intuitively, we are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Observing&lt;/strong&gt; a materialized payoff $p_i$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inverting&lt;/strong&gt; $g$ to recover the latent skill gap $\hat\delta_{i, \, j}$ that was most likely to produce $p_i$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Comparing&lt;/strong&gt; that inferred gap to our current belief of the skill gap $r_i - r_j$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deriving&lt;/strong&gt; the change to $r_i$ and $r_j$ would bring our belief closer to $\hat\delta_{i, \, j}$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Then, the gradient-ascent update with step size $k$,&lt;/p&gt;
$$
\begin{equation}
    \bold{r}_{t + 1} 
    \gets 
    \bold{r}_{t} 
    + k\nabla_{\bold{r}}\log\mathcal{J}_\mathrm{MAP}(\theta_i, \, \theta_j; \, \hat\delta_{i, \, j}),
\end{equation}
$$&lt;p&gt;offers a complete recovery (and generalization) of the Elo update after an observed payoff $p_i$.&lt;/p&gt;
&lt;h3 id=&#34;discussion&#34;&gt;Discussion&lt;/h3&gt;
&lt;h4 id=&#34;procedural-discrepancy&#34;&gt;Procedural Discrepancy&lt;/h4&gt;
&lt;p&gt;Usually, implementations of Elo updates do not consider a prior. Instead, they simply initialize parameters at some default amount, then do MLE (as opposed to MAP estimation) to produce gradient updates. I decided to display the full MAP estimate because I think it is more principled; if you believe that ratings &amp;ldquo;start off&amp;rdquo; at some amount, that constitutes a bayesian prior in my eyes.&lt;/p&gt;
&lt;h4 id=&#34;distribution-discrepancy&#34;&gt;Distribution Discrepancy&lt;/h4&gt;
&lt;p&gt;The Elo rating system assumes a logistic distribution on player performance, not gaussian. However, the above procedure will invariantly recover Elo updates as presented in the &lt;a href=&#34;#elo-ratings-and-updates&#34;&gt;background section&lt;/a&gt; with both distributions (at least in form). I thought it would be somewhat interesting to make it gaussian.&lt;/p&gt;
&lt;h4 id=&#34;fixed-parameters&#34;&gt;Fixed Parameters&lt;/h4&gt;
&lt;p&gt;In theory, one could estimate the variance parameters using the exact same procedure, by taking the gradient of the joint likelihood with respect to them in addition to the means (the ratings). Surprisingly, people do things similar to this &amp;ndash; although not in this particular way. See the &lt;a href=&#34;https://en.wikipedia.org/wiki/Glicko_rating_system&#34;&gt;Glicko rating system&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;redundancy-with-g&#34;&gt;Redundancy with $g$&lt;/h4&gt;
&lt;p&gt;You may have noticed that throughout our derivations (most notably in equations $(7)$ and $(8)$) there are $g(\hat\delta_{i, \, j})$ terms that can be safely replaced with $p_i$ by definition, and can be therefore seen as redundant. This is a completely accurate observation.&lt;/p&gt;
&lt;p&gt;I decided to make $g$ explicit to make the fundamental link between payoffs and performance differentials also explicit, which is something I consider to be a lot more principled. In fact, $g$ does not need to be strictly monotonic, as we never explicitly evaluate $g^{-1}(\small\bullet)$. However, not satisfying this property may result in a lack of parameter identifiability, which is easy to forget if you discard the symbol early on.&lt;/p&gt;
&lt;h4 id=&#34;weak-ordering&#34;&gt;Weak Ordering&lt;/h4&gt;
&lt;p&gt;It is important to acknowledge that mapping player skill to $\mathbb{R}$ and then using $\leq$ to order players is a fundamentally misguided approach to how the world works. In doing so, we establish a weak ordering among players, but completely ignore that some players have qualities that make them strong against some players and weak against others (in a manner that is potentially cyclic).&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;To illustrate this, consider three players of rock-paper-scissors. One always plays rock, one always plays paper, and the other scissors. You will find that there is no way of assigning them a real number such that the player with the highest number beats both of the other players in expectation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Still, sometimes we are forced to make rankings which make sense &lt;em&gt;in expectation&lt;/em&gt;. In the real world, there is sufficient variance in player attributes that there are actors that can consistently beat some others. Here, systems such as Elo&amp;rsquo;s bring real utility. But as a human, you should trust your intuition more than some potentially senseless number.&lt;/p&gt;
&lt;h4 id=&#34;outcome-prediciton&#34;&gt;Outcome Prediciton&lt;/h4&gt;
&lt;p&gt;Further expanding on the inadequacy of ranking players via weak order, consider the very plausible machine learning task of outcome prediction, say, for the game of &lt;a href=&#34;https://en.wikipedia.org/wiki/Basketball&#34;&gt;Basketball&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It is tempting to, for example, train a network $f_\theta : \mathbb{R}^n \to \mathbb{R}$ on $n$-dimensional encodings of teams to predict a scalar value, where you then train in tandem over historic game outcomes $\langle ((a, b), \, y)_i \rangle_{i \in D}$.&lt;/p&gt;
&lt;p&gt;Here, teams $a, \, b \in \mathbb{R}^n$ played each other and achieved outcome $y \in \{-1, 1\}$ for each match $i \in D$. One could optimize under the following loss,&lt;/p&gt;
$$
    \mathcal{L}((a, \, b), \, y; \, \theta) 
    = \log\exp\bigl( 1 + y(f_\theta(a) - f_\theta(b))\bigr) 
    + \lambda(f_\theta(a) + f_\theta(b)),
$$&lt;p&gt;where the regularization term helps with stability. Then, $f_\theta$ would essentially become a rating estimator. Whoever does this, however, will have the same fundamental problem as the Elo system; a weak order cannot capture the potentialy cyclic structure of actors&amp;rsquo; dominance on each other.&lt;/p&gt;
&lt;p&gt;The solution, of course, is to instead train another model $f_\theta : \mathbb{R}^{2n} \to \mathbb{R}$ that admits pairings as an input via concatentaion, and implements typical binary cross-entropy loss:&lt;/p&gt;
$$
    \mathcal{L}((a, \, b), \, y; \, \theta) 
    = -\bold{I}_y\,\log\bigl(\sigma(f_\theta(a \Vert b))\bigr) - (1 - \bold{I}_y)\,\log\bigl(1-\sigma(f_\theta(a \Vert b))\bigr).
$$&lt;p&gt;However, there is no free lunch &amp;ndash; when training over &lt;em&gt;pairs&lt;/em&gt; of teams in $T$, the sample space of the task grows with the size of $T \times T$, naturally increasing the amount of out-of-distribution data for your model quadratically. Of course, this problem was ignored by the first formulation too, just in a different way.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;gaussian-convolution&#34;&gt;Gaussian Convolution&lt;/h3&gt;
&lt;p&gt;Here, I justify equation $(6)$ by instantiating a proof of the fact that the convolution of two gaussians is another gaussian determined by the parameters of the original gaussians.&lt;/p&gt;
&lt;h4 id=&#34;proof&#34;&gt;Proof&lt;/h4&gt;
&lt;p&gt;This was made via ChatGPT with &lt;code&gt;o4-mini-high&lt;/code&gt; and adjusted by me, because you can probably find it in a textbook somewhere. Let&lt;/p&gt;
$$
    f(d)=\frac{1}{\sqrt{2\pi}\,\sigma_1}\exp\!\Bigl(-\frac{(d-\mu_1)^2}{2\,\sigma_1^2}\Bigr),
    \quad
    g(d)=\frac{1}{\sqrt{2\pi}\,\sigma_2}\exp\!\Bigl(-\frac{(d-\mu_2)^2}{2\,\sigma_2^2}\Bigr).
$$&lt;p&gt;We wish to show&lt;/p&gt;
$$
    \int_{-\infty}^{\infty} f(d)\,g(d)\,dd
    =\frac{1}{\sqrt{2\pi\,(\sigma_1^2+\sigma_2^2)}}\,
    \exp\!\Bigl(-\frac{(\mu_1-\mu_2)^2}{2\,(\sigma_1^2+\sigma_2^2)}\Bigr).
$$&lt;p&gt;Set $A=\sigma_1^2$ and $B=\sigma_2^2$. Then,&lt;/p&gt;
$$
    f(d)\,g(d)
    =\frac{1}{2\pi\sqrt{AB}}
    \exp\!\Bigl(-\tfrac12\bigl[\tfrac{(d-\mu_1)^2}{A}+\tfrac{(d-\mu_2)^2}{B}\bigr]\Bigr).
$$&lt;p&gt;Combine quadratic terms:&lt;/p&gt;
$$
    B(d-\mu_1)^2 + A(d-\mu_2)^2
    =(A+B)\Bigl(d-\frac{B\mu_1 + A\mu_2}{A+B}\Bigr)^2
    +\frac{AB}{A+B}(\mu_1-\mu_2)^2.
$$&lt;p&gt;Define&lt;/p&gt;
$$
    m=\frac{B\mu_1 + A\mu_2}{A+B},
    \quad
    C=\frac{AB}{A+B}.
$$&lt;p&gt;Then,&lt;/p&gt;
$$
    \int f(d)\,g(d)\,dd
    =\frac{1}{2\pi\sqrt{AB}}
    \int
    \exp\!\Bigl(-\tfrac12\bigl[\tfrac{(d-m)^2}{C}+\tfrac{(\mu_1-\mu_2)^2}{A+B}\bigr]\Bigr)
    \,dd.
$$&lt;p&gt;Factor out the constant term and use&lt;/p&gt;
$$
    \int \exp\Bigl(-\frac{(d-m)^2}{2C}\Bigr) \, dd
    =\sqrt{2\pi\,C}.
$$&lt;p&gt;Hence,&lt;/p&gt;
$$
\begin{aligned}
    \int f(d)\,g(d)\,dd
    &amp;=\frac{\sqrt{2\pi\,C}}{2\pi\sqrt{AB}}
    \exp\!\Bigl(-\frac{(\mu_1-\mu_2)^2}{2\,(A+B)}\Bigr)\\
    &amp;=\frac{1}{\sqrt{2\pi\,(A+B)}}
    \exp\!\Bigl(-\frac{(\mu_1-\mu_2)^2}{2\,(A+B)}\Bigr). \quad \square
\end{aligned}
$$&lt;h4 id=&#34;instantiation&#34;&gt;Instantiation&lt;/h4&gt;
&lt;p&gt;Consider the expression which $(6)$ was derived from,&lt;/p&gt;
$$
\begin{aligned}
    &amp;\int
       \frac{1}{\sqrt{2\pi}\,\sigma_\varepsilon}
       \exp\!
       \overbrace{
        \Bigl(-\frac{\bigl(g(\hat\delta_{i, \, j}) - d\bigr)^2}{2\,\sigma_\varepsilon^2}\Bigr)
       }^{
        \text{Quadratic term is symmetric.}
       }
       \;|g&#39;(\hat\delta_{i, \, j})|\; \\
    &amp;\quad\;\quad\;\times \frac{1}{\sqrt{2\pi(\sigma_i^2+\sigma_j^2)}}
       \exp\!\Bigl(-\frac{(d - (r_i - r_j))^2}{2(\sigma_i^2+\sigma_j^2)}\Bigr)
    \,dd.
\end{aligned}
$$&lt;p&gt;Now, use the substitutions&lt;/p&gt;
$$
    \mu_1 = g(\hat\delta_{i, \, j}),
    \quad
    \mu_2 = r_i - r_j,
    \quad
    A = \sigma_\varepsilon^2,
    \quad
    B = \sigma_i^2 + \sigma_j^2,
$$&lt;p&gt;and re-attach the Jacobian factor $|g^\prime(\hat\delta_{i, \, j})|$ to recover&lt;/p&gt;
$$
\mathcal{J}(\theta_i,\theta_j;\hat\delta_{i, \, j})
=\frac{|g&#39;(\hat\delta_{i, \, j})|}
      {\sqrt{2\pi\,(\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2)}}\,
  \exp\!\Bigl(-\frac{(g(\hat\delta_{i, \, j}) - (r_i - r_j))^2}
                       {2\,(\sigma_\varepsilon^2 + \sigma_i^2 + \sigma_j^2)}\Bigr).
$$&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;I modified a term in $e_p$ to exclude scaling factors, to make it look less crazy. These scaling factors make the resulting ratings quite practical by allowing one to make comparisons like &amp;ldquo;player $i$ is 10x better than $j$ if $i$&amp;rsquo;s rating is 400 points higher.&amp;rdquo;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Taking the $\log$ makes it easier to deal with multiple samples, as it turns the product in $(1)$ into a sum. But here, we only use one sample, so it is useless. However, tradition is important for learning.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Poem 1. &#34;Delia&#34;</title>
      <link>http://localhost:1313/poem-1.-delia/</link>
      <pubDate>Sun, 27 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/poem-1.-delia/</guid>
      <description>&lt;p&gt;Madre que no te suelta el estandarte,&lt;br&gt;
madre de selva que te cubre como yedra;&lt;br&gt;
me arrulla desde la penumbra,&lt;br&gt;
me susurra el nombre de Dios.&lt;br&gt;
Ya quítame de aquí que me muero, madre,&lt;br&gt;
dame las palabras que me corresponden,&lt;br&gt;
sacude desde tu sigilo mi sangre,&lt;br&gt;
hazme llegar tu amor.&lt;br&gt;
Soledad eterna y vida corta,&lt;br&gt;
no te vayas a olvidar de mí.&lt;br&gt;
Madre que a ciegas todo lo ve;&lt;br&gt;
corazón de parota, palabras de luz.&lt;br&gt;
Eres la cumbre de este desierto,&lt;br&gt;
autora del método mío,&lt;br&gt;
madre de todo.&lt;br&gt;
Mi primer amor, también el último,&lt;br&gt;
mi castillo, mi escudo, mi ángel.&lt;br&gt;
Águila de quinientas virtudes,&lt;br&gt;
reguilete infinito de colores,&lt;br&gt;
piedra de orgullo inexorable.&lt;br&gt;
Arbol terrestre que toca el cielo,&lt;br&gt;
sosiego inminente,&lt;br&gt;
calor solar.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>N-Gram Model of Optimal Policy on Interpretable Abstractions</title>
      <link>http://localhost:1313/n-gram-model-of-optimal-policy-on-interpretable-abstractions/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/n-gram-model-of-optimal-policy-on-interpretable-abstractions/</guid>
      <description>&lt;aside id=&#34;toc&#34;&gt;
    &lt;details&gt;
        &lt;summary&gt;&amp;nbsp;&lt;strong&gt; Table of contents&lt;/strong&gt;&lt;/summary&gt;
        &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#background&#34;&gt;Background&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#n-gram-modeling&#34;&gt;$N$-Gram Modeling&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#rules-of-thumb&#34;&gt;Rules of Thumb&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#markov-abstractions&#34;&gt;Markov Abstractions&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#model&#34;&gt;Model&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#training&#34;&gt;Training&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#sources&#34;&gt;Sources&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#sinks&#34;&gt;Sinks&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#inference&#34;&gt;Inference&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#remarks&#34;&gt;Remarks&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#explorations&#34;&gt;Explorations&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#credits&#34;&gt;Credits&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
    &lt;/details&gt;
&lt;/aside&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Generally, the choice of functional form of a policy model and of the domain that it operates on forms the basis of interpretability. Domains that are the image of class-valued abstractions of the observable state space are desireable because humans excel at visual classification tasks that map onto (largely) discrete characteristics. Hence, we provide an interpretable functional form that is valid over multiclass spaces in the form of an $n$-gram model approximation of dynamics under optimal policy.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h3 id=&#34;n-gram-modeling&#34;&gt;$N$-Gram Modeling&lt;/h3&gt;
&lt;p&gt;$n$-gram models were developed as a rudimentary statistical model of language. Assuming an $n^{th}$-order &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_property&#34;&gt;Markov property&lt;/a&gt; on the probability of a word $w_{t + 1}$ at discrete time $t + 1$ given a history $\langle w_i \rangle_{i \in [1, \, t]}$,&lt;/p&gt;
$$
\begin{equation}
  P(w_1, \, \ldots, w_{t + 1}) =
  P(w_1, \dots, w_{t - n - 1}) \prod_{i = 0}^{n - 1} P(w_{t+1} \mid w_{t-n}, \dots, w_t),
\end{equation}
$$&lt;p&gt;straightforward &lt;a href=&#34;https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&#34;&gt;maximum likelihood estimation&lt;/a&gt; shows that this probability is the proportion of times that the sequence $\langle w_{t-n}, \, \ldots, w_t \rangle$ appears before $w_{t + 1}$ in observations. This is can be seen as frequentist inference, making the probability measure intuitive.&lt;/p&gt;
&lt;p&gt;When applied to a set of symbols (words) $S$, such a model implies a Markov chain over the product $S^n = S \times \cdots \times S$. It follows that the chain&amp;rsquo;s &lt;a href=&#34;https://en.wikipedia.org/wiki/Stochastic_matrix&#34;&gt;stochastic matrix&lt;/a&gt; $\Pi$ is an element of $\mathbb{R}^{k \times k^n}$ with $k = |S|$, so the number of learnable parameters grows exponentially with the order of the model for a fixed $S$.&lt;/p&gt;
&lt;p&gt;As a result of upholding the Markov property, $n$-gram models are stationary&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. This flaw makes them incompatible with natural language to any useful extent, and is directly addressed by modern language models through mechanisms like &lt;a href=&#34;https://en.wikipedia.org/wiki/Attention_(machine_learning)&#34;&gt;attention&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;rules-of-thumb&#34;&gt;Rules of Thumb&lt;/h3&gt;
&lt;p&gt;Many heuristics taught in strategic decision-making can be described to be conditionals on the result of classification exercises. For example, there is a rule of thumb in Chess which calls for protecting one&amp;rsquo;s own king if it is open.&lt;/p&gt;
&lt;p&gt;When implementing this heuristic, a player performs classification via a mapping $\phi : S \to \{\text{Yes}, \, \text{No}\}$ from the set of board states to an answer to the heuristic&amp;rsquo;s condition, where experience insists that if a player&amp;rsquo;s $\phi$ is sufficiently close to ground truth, they obtain a performance improvement in expectation.&lt;/p&gt;
&lt;p&gt;Naturally, the complexity involved in evaluating a classification $\phi_h(s)$ for some state $s \in S$ should be minimal so that its heuristic $h$ can be implemented without computer assistance. In many cases, their simplicity to humans (i.e., how intuitive they are) directly translates to the simplicity of implementing them in other models of computation. Put simply, it is generally easy to program such functions.&lt;/p&gt;
&lt;p&gt;However, humans can obtain an &lt;em&gt;unexplainable&lt;/em&gt; intuitive understanding of a game. In such cases, the classification exercises they carry out for their expert heuristics are mappings onto a set of abstract characteristics (e.g., area &amp;lsquo;crowdedness&amp;rsquo; in Chess). This can be seen as &lt;a href=&#34;https://en.wikipedia.org/wiki/Feature_learning&#34;&gt;representation learning&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But even in these cases, it is relatively simple to train a model which replicates a human&amp;rsquo;s capacity to perform classification for their own expert-level heuristics by having them label training datasets by hand. Hence, one can generally assume access to efficient classifiers for human-interpretable features.&lt;/p&gt;
&lt;h3 id=&#34;markov-abstractions&#34;&gt;Markov Abstractions&lt;/h3&gt;
&lt;p&gt;Given an abstraction $\phi : S \to Z$ over a state set $S$, the lack of an injectivity constraint could produce a situation where, for a policy $\pi_S : S \to S$ with $\pi(s) = a$ and $\pi(s^\prime) = b$ on distinct $a, \, b, \, s, \, s^\prime \in S$,&lt;/p&gt;
$$
\begin{equation}
  \phi(s) = \phi(s^\prime) \;\; \text{and} \;\; \phi(a) \neq \phi(b).
\end{equation}
$$&lt;p&gt;Hence, learning a counterpart $\pi_Z : Z \to Z$ which preserves the information in $\pi_S$ could be impossible, as $\pi_Z(\alpha(s)) = \pi_Z(\alpha(s^\prime))$ would have to &amp;lsquo;retain&amp;rsquo; the information of both $\pi_S(s) = a$ and $\pi_S(s^\prime) = b$. Such an abstraction $\phi$ is said to not be Markov, as its image contains insufficient information to induce a dynamics that corresponds to the behavior specified by $\pi_S$ in $S$.&lt;/p&gt;
&lt;p&gt;In the context of interpretable rules of thumb, reducing the state space $S$ to significantly smaller abstract spaces (e.g., taking decision in $\{\text{Yes}, \, \text{No}\}$ while implementing a heuristic) nearly guarantees that the abstraction which mediated the reduction is not Markov&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;p&gt;Let $\langle \phi^{(\alpha)} : S \to Z^{(\alpha)} \rangle_{\alpha \in \Alpha}$ be a collection of abstractions enumerated in $\Alpha$, and $\pi_S : S \to S$ a policy over $S$. We propose modeling class-conditional transition probability distributions,&lt;/p&gt;
$$
\begin{equation}
  P^{(\alpha)}_{t+1}(k) = P[\phi^{(\alpha)}(\pi^{t + 1}(s)) = k \; | \; \phi^{(\alpha)}(\pi^t(s)) = k_t, \, \ldots, \, \phi^{(\alpha)}(\pi^0(s)) = k_0],
\end{equation}
$$&lt;p&gt;of the elements $k_i \in Z^{(\alpha)}$ via an $n$-gram model. This effectively establishes sequences in $\phi^{(\alpha)}(S)$ via repeated aplication of $\pi$ within $S$ (following the dynamics of $\pi$), so that in the above equation, we allow $\pi^t(s) = \pi_t(\pi_{t-1}(\ldots\pi_1(s)))$.
This yields a collection of stochastic matrices $\langle  \Pi^{(\alpha)} \rangle_{\alpha \in \Alpha}$ with&lt;/p&gt;
$$
\Pi^{(\alpha)}_{i, j} = P[\, i \text{ is observed at time } t \; | \; j \text{ is observed immediately before}\,],
$$&lt;p&gt;where $i \in Z^{(\alpha)}$ and $j \in (Z^{(\alpha)})^n$. The amount of learnable parameters (i.e., the size) of such a model $M = \langle  \Pi^{(a)} \rangle_{\alpha \in \Alpha}$ is therefore&lt;/p&gt;
$$
\begin{equation}
  |M| = \sum_{\alpha \in \Alpha} |Z^{(\alpha)}|^n \, (|Z^{(\alpha)}| - 1).
\end{equation}
$$&lt;p&gt;The finalized abstract policy $\pi_Z$ would use this model to operate on $Z = \large{\times_{\alpha \in \Alpha}} Z^{(\alpha)}$ (see the &lt;a href=&#34;#inference&#34;&gt;inference section&lt;/a&gt; for a high-level overview of evaluation). By operating on the cross-product of multiple sufficiently independent heuristics, $\pi_Z$ could closely approximate $\pi_S$ while remaining interpretable.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;training&#34;&gt;Training&lt;/h2&gt;
&lt;p&gt;The parameter space for a model $M$ of order $n$ is precisely&lt;/p&gt;
$$
\begin{equation}
  \Theta =
  \large{\times_{\alpha \in \Alpha}}
  \large{\times_{k \in Z^{(\alpha)}}}
  \bold{S}^{|Z^{(\alpha)}|^n},
\end{equation}
$$&lt;p&gt;(where $\bold{S}^d$ denotes the $d$-dimensional unit sphere). Finding optimal parameters $\theta^* \in \Theta$ follows standard procedure as in any $n$-gram model. Hence, we simply provide the generic closed-form solution written in terms of the objects at hand,&lt;/p&gt;
$$
\begin{equation}
 \Pi^{(\alpha)}_{i, j} = \frac{1}{N}
 \sum_{s \in S}
  I^{(\alpha)}_{i,j}(\pi^n(s), \langle \pi^i(s) \rangle_{i \in [0, \, n)}),
\end{equation}
$$&lt;p&gt;where&lt;/p&gt;
$$
\begin{equation*}
 I^{(\alpha)}_{i,j}(a, \langle b_i \rangle_{i \in [0, \, n)}) =
 \begin{cases}
       1 &amp; \text{if } \; \phi^{(\alpha)}(a) = i \; \text{ and } \; \phi^{(\alpha)}(b) = j, \\
       0 &amp; \text{otherwise},
  \end{cases}
\end{equation*}
$$&lt;p&gt;and $N$ is the number of length-$(n + 1)$ contiguous subsequences in the dynamics of $\pi$, which can be easily sketched while computing the sum in $(5)$.&lt;/p&gt;
&lt;h3 id=&#34;sources&#34;&gt;Sources&lt;/h3&gt;
&lt;p&gt;The nature of the policy operator $\pi$ is such that there exists some $s \in S$ wihtout an $s^\prime$ with $\pi(s^\prime) = s$. Here, $s$ is called a source within the dynamics of $\pi$. This constitutes a problem, as the start $s_0$ of the game for which $S$ is a state space is necessarily a source (which may not be unique); therefore, an attempt to find an $n$-length sequence of moves leading up to a state less than $n$ applications of $\pi$ away from a source in its dynamics may fail.&lt;/p&gt;
&lt;p&gt;This is important because it is a step necessary to compute the $\Pi^{(\alpha)}_{i, j}$$^{\text{th}}$ parameter of the model, where $i$ is the parameter that is too close to a source to have a valid $n$-gram history. A solution which does not significantly alter transition distributions of $\Pi^{(\alpha)}$ is to sample missing elements of $n$-gram histories from a uniform distribution while computing its entries. If this measure is taken, $N$ can be set to $|S|$ in $(5)$, avoiding the need for sketching proportions.&lt;/p&gt;
&lt;h3 id=&#34;sinks&#34;&gt;Sinks&lt;/h3&gt;
&lt;p&gt;In many traditional definitions of a policy $\pi$, there may exist elements $s^\prime_i$ of $S$ over which $\pi$ is not defined, as they are terminal in the game under representation. These are sinks in the dynamics of $\pi$, and should never be considered as part of a history while computing model parameters.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;inference&#34;&gt;Inference&lt;/h2&gt;
&lt;p&gt;When at a state $s \in S$, a human player can consider the set of next possible states $t(s)$ (where the transition function $t : S \to \mathcal{P}(S)$ is set-valued). Optimally, combinatorial optimization would be done across all elements $s^\prime \in t(s)$ under the MLE objective of maximizing the probability that their action is observed across all abstract state space transitions.&lt;/p&gt;
&lt;p&gt;While this is possible to an extent due to the simplicity of the abstractions in consideration (which map onto small sets of classes, reducing maximization objectives during MLE), the true value of the model is in the subjective analysis of each $\Pi^{(\alpha)}$. Additionally, quantitative techniques (such as finding the static distribution and convergence rate of these matrices) may illustrate interpretable patterns in the dynamics of $\pi$, depending on $\langle \phi^{(\alpha)} \rangle$.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;remarks&#34;&gt;Remarks&lt;/h2&gt;
&lt;p&gt;Establishing an approximation of optimal policy in the form of a Markov process provides an interpretable functional representation that is able to work with intuitive abstractions. Thus, it is a valid representation of a praxis, and the above methods effectively &amp;rsquo;translate&amp;rsquo; from policies of arbitrary form.&lt;/p&gt;
&lt;h3 id=&#34;explorations&#34;&gt;Explorations&lt;/h3&gt;
&lt;p&gt;The following are left as potential avenues of analysis relating to the model family.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Smoothing techniques, and an analysis of their benefit in the context of optimal policy.&lt;/li&gt;
&lt;li&gt;Non-interpretability of $n$-gram model successors; in particular transformer attention.&lt;/li&gt;
&lt;li&gt;Skip-gram models as an extension of this family.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;credits&#34;&gt;Credits&lt;/h2&gt;
&lt;p&gt;Thank you to my good friend Humberto Gutierrez for spending late nights discussing the concept of policy abstraction with me, and helping me organize many ideas about policies over continuous abstractions.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;A stationary model&amp;rsquo;s probability assignments are invariant with respect to shifts in the time index.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Which is a way of saying that rules of thumb are not globally applicable.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Representation Concepts in Game-Theoretic Systems</title>
      <link>http://localhost:1313/representation-concepts-in-game-theoretic-systems/</link>
      <pubDate>Sat, 20 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/representation-concepts-in-game-theoretic-systems/</guid>
      <description>&lt;aside id=&#34;toc&#34;&gt;
    &lt;details&gt;
        &lt;summary&gt;&amp;nbsp;&lt;strong&gt; Table of contents&lt;/strong&gt;&lt;/summary&gt;
        &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#materials&#34;&gt;Materials&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#errata&#34;&gt;Errata&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#background&#34;&gt;Background&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#game-theory&#34;&gt;Game theory&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#computer-science&#34;&gt;Computer science&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#representation&#34;&gt;Representation&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#rulesets&#34;&gt;Rulesets&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#abstraction&#34;&gt;Abstraction&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#design&#34;&gt;Design&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#interface-items&#34;&gt;Interface items&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#parallel-dp&#34;&gt;Parallel DP&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#meta-content&#34;&gt;Meta-content&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
    &lt;/details&gt;
&lt;/aside&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;I gave an introductory talk about how computer systems represent, compute, and store noteworthy attributes about a particular class of games. This was part of &lt;a href=&#34;http://kyleburke.info/sprouts/&#34;&gt;Sprouts &amp;lsquo;24&lt;/a&gt;, an undergraduate-oriented conference primarily dedicated to combinatorial game theory.&lt;/p&gt;
&lt;p&gt;Here, I share the materials I used during my presentation and share a longer-form (but very different) exploration of the topic I covered. Generically, it can be useful for all problems where one must run a domain-specific algorithm on a graph that is not materialized in memory, but can be traversed in linear time from a starting node and a set of functions that derive adjacent edges and nodes from existing ones (a so-called &lt;a href=&#34;https://en.wikipedia.org/wiki/Implicit_graph&#34;&gt;implicit graph&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;As a concrete case of this abstract class of problems, I present concepts that support the process of finding a Nash Equilibrium for a specific subclass of games through cousins of the minimax algorithm. However, these concepts are also applicable to other such problems (e.g., the membership problem&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; for decidable subclasses of context-free grammars).&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;materials&#34;&gt;Materials&lt;/h2&gt;
&lt;p&gt;The slides I used during my talk can be found below. Anyone can use them without my permission.&lt;/p&gt;
&lt;script type=&#34;text/javascript&#34; src= &#39;/js/pdf-js/build/pdf.js&#39;&gt;&lt;/script&gt;

&lt;style&gt;
  #embed-pdf-container {
    position: relative;
    width: 100%;
    height: auto;
    min-height: 20vh;
     
  }

  .pdf-canvas {
    border: 1px solid black;
    direction: ltr;
    width: 100%;
    height: auto;
    display: none;
  }

  #the-canvas {
    border: 1px solid black;
    direction: ltr;
    width: 100%;
    height: auto;
    display: none;
  }


  .pdf-loadingWrapper {
    display: none;
    justify-content: center;
    align-items: center;
    width: 100%;
    height: 350px;
  }

  .pdf-loading {
    display: inline-block;
    width: 50px;
    height: 50px;
    border: 3px solid #d2d0d0;;
    border-radius: 50%;
    border-top-color: #383838;
    animation: spin 1s ease-in-out infinite;
    -webkit-animation: spin 1s ease-in-out infinite;
  }

  



  #overlayText {
    word-wrap: break-word;
    display: grid;
    justify-content: end;
  }

  #overlayText a {
    position: relative;
    top: 10px;
    right: 4px;
    color: #000;
    margin: auto;
    background-color: #eeeeee;
    padding: 0.3em 1em;
    border: solid 2px;
    border-radius: 12px;
    border-color: #00000030;
    text-decoration: none;
  }

  #overlayText svg {
    height: clamp(1em, 2vw, 1.4em);
    width:  clamp(1em, 2vw, 1.4em);
  }



  @keyframes spin {
    to { -webkit-transform: rotate(360deg); }
  }
  @-webkit-keyframes spin {
    to { -webkit-transform: rotate(360deg); }
  }
  &lt;/style&gt;&lt;div class=&#34;embed-pdf-container&#34; id=&#34;embed-pdf-container-de1ff50c&#34;&gt;
    &lt;div class=&#34;pdf-loadingWrapper&#34; id=&#34;pdf-loadingWrapper-de1ff50c&#34;&gt;
        &lt;div class=&#34;pdf-loading&#34; id=&#34;pdf-loading-de1ff50c&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;canvas class=&#34;pdf-canvas&#34; id=&#34;pdf-canvas-de1ff50c&#34;&gt;&lt;/canvas&gt;
&lt;/div&gt;

&lt;div class=&#34;pdf-paginator&#34; id=&#34;pdf-paginator-de1ff50c&#34;&gt;
    &lt;button id=&#34;pdf-prev-de1ff50c&#34;&gt;Previous&lt;/button&gt;
    &lt;button id=&#34;pdf-next-de1ff50c&#34;&gt;Next&lt;/button&gt; &amp;nbsp; &amp;nbsp;
    &lt;span&gt;
      &lt;span class=&#34;pdf-pagenum&#34; id=&#34;pdf-pagenum-de1ff50c&#34;&gt;&lt;/span&gt; / &lt;span class=&#34;pdf-pagecount&#34; id=&#34;pdf-pagecount-de1ff50c&#34;&gt;&lt;/span&gt;
    &lt;/span&gt;
    &lt;a class=&#34;pdf-source&#34; id=&#34;pdf-source-de1ff50c&#34; href=&#34;http://localhost:1313/pdf/slides-sprouts-2024.pdf&#34;&gt;[pdf]&lt;/a&gt;
&lt;/div&gt;

&lt;noscript&gt;
View the PDF file &lt;a class=&#34;pdf-source&#34; id=&#34;pdf-source-noscript-de1ff50c&#34; href=&#34;http://localhost:1313/pdf/slides-sprouts-2024.pdf&#34;&gt;here&lt;/a&gt;.
&lt;/noscript&gt;

&lt;script type=&#34;text/javascript&#34;&gt;
    (function(){
    var url = &#39;\/pdf\/slides-sprouts-2024.pdf&#39;;

    var hidePaginator = &#34;&#34; === &#34;true&#34;;
    var hideLoader = &#34;&#34; === &#34;true&#34;;
    var selectedPageNum = parseInt(&#34;&#34;) || 1;

    
    var pdfjsLib = window[&#39;pdfjs-dist/build/pdf&#39;];

    
    if (pdfjsLib.GlobalWorkerOptions.workerSrc == &#39;&#39;)
      pdfjsLib.GlobalWorkerOptions.workerSrc = &#34;http:\/\/localhost:1313\/&#34; + &#39;js/pdf-js/build/pdf.worker.js&#39;;

    
    var pdfDoc = null,
        pageNum = selectedPageNum,
        pageRendering = false,
        pageNumPending = null,
        scale = 3,
        canvas = document.getElementById(&#39;pdf-canvas-de1ff50c&#39;),
        ctx = canvas.getContext(&#39;2d&#39;),
        paginator = document.getElementById(&#34;pdf-paginator-de1ff50c&#34;),
        loadingWrapper = document.getElementById(&#39;pdf-loadingWrapper-de1ff50c&#39;);


    
    showPaginator();
    showLoader();

    

    function renderPage(num) {
      pageRendering = true;
      
      pdfDoc.getPage(num).then(function(page) {
        var viewport = page.getViewport({scale: scale});
        canvas.height = viewport.height;
        canvas.width = viewport.width;

        
        var renderContext = {
          canvasContext: ctx,
          viewport: viewport
        };
        var renderTask = page.render(renderContext);

        
        renderTask.promise.then(function() {
          pageRendering = false;
          showContent();

          if (pageNumPending !== null) {
            
            renderPage(pageNumPending);
            pageNumPending = null;
          }
        });
      });

      
      document.getElementById(&#39;pdf-pagenum-de1ff50c&#39;).textContent = num;
    }

    

    function showContent() {
      loadingWrapper.style.display = &#39;none&#39;;
      canvas.style.display = &#39;block&#39;;
    }

    

    function showLoader() {
      if(hideLoader) return
      loadingWrapper.style.display = &#39;flex&#39;;
      canvas.style.display = &#39;none&#39;;
    }

    

    function showPaginator() {
      if(hidePaginator) return
      paginator.style.display = &#39;block&#39;;
    }

    

    function queueRenderPage(num) {
      if (pageRendering) {
        pageNumPending = num;
      } else {
        renderPage(num);
      }
    }

    

    function onPrevPage() {
      if (pageNum &lt;= 1) {
        return;
      }
      pageNum--;
      queueRenderPage(pageNum);
    }
    document.getElementById(&#39;pdf-prev-de1ff50c&#39;).addEventListener(&#39;click&#39;, onPrevPage);

    

    function onNextPage() {
      if (pageNum &gt;= pdfDoc.numPages) {
        return;
      }
      pageNum++;
      queueRenderPage(pageNum);
    }
    document.getElementById(&#39;pdf-next-de1ff50c&#39;).addEventListener(&#39;click&#39;, onNextPage);

    

    pdfjsLib.getDocument(url).promise.then(function(pdfDoc_) {
      pdfDoc = pdfDoc_;
      var numPages = pdfDoc.numPages;
      document.getElementById(&#39;pdf-pagecount-de1ff50c&#39;).textContent = numPages;

      
      if(pageNum &gt; numPages) {
        pageNum = numPages
      }

      
      renderPage(pageNum);
    });
    })();
&lt;/script&gt;

&lt;h3 id=&#34;errata&#34;&gt;Errata&lt;/h3&gt;
&lt;p&gt;Here are the mistakes I have found in the slides:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In slide 10, the first bullet point should also restrain the set of games under consideration to be extensive-form and non-collaborative, as implied by the subsequent definition in slides 11-15.&lt;/li&gt;
&lt;li&gt;In slide 20, the formulation $\langle N, S, p, u \rangle$ should also include a transition function $t : S \to \mathcal{P}(S)$, where if $s$ is a state corresponding to history $h$, then the history $h&amp;rsquo;$ corresponding to $s&amp;rsquo;$ should be the same as $h$ with an additional action appended for all $s&amp;rsquo; \in t(s)$.&lt;/li&gt;
&lt;li&gt;In slide 28, the partition should not necessarily minimize the sum of the conductance of all cuts that produce the partition. Instead, the ideal partition would be a solution to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Graph_partition#:~:text=%5B4%5D-,Problem,-%5Bedit%5D&#34;&gt;balanced partition problem&lt;/a&gt;, where optimal parameters are determined from hardware-related constraints (such as the cost of inter-process communication). The goal is to balance parallelism with its own overhead.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;In the interest of accessibility, I will briefly cover useful basics in game theory and computer science that seldom find their way into students&amp;rsquo; syllabi or are otherwise worth refreshing. If you think you can safely skip this, you are probably right.&lt;/p&gt;
&lt;h3 id=&#34;game-theory&#34;&gt;Game theory&lt;/h3&gt;
&lt;p&gt;The generic setup of a game is some amount of &amp;ldquo;players&amp;rdquo; taking actions according to their own interests or preferences, potentially affecting other players in the process. From the point of view of a single player, a game is an optimization problem that seeks to find an &amp;ldquo;optimal strategy&amp;rdquo; from the information available to them. This is an assumption known as &amp;ldquo;individual rationality&amp;rdquo; that pervades most of game theory.&lt;/p&gt;
&lt;p&gt;But from a global point of view, there is no obvious question to ask about a game. This is why games are not problems; they are situations that we can ask different questions about. But &lt;em&gt;per se&lt;/em&gt;, games are not aching to be solved. To ask specific questions with some hope of rigor, a lot of effort has been placed into defining classes of games that posses different characteristics.&lt;/p&gt;
&lt;h4 id=&#34;taxonomy-of-games&#34;&gt;Taxonomy of games&lt;/h4&gt;
&lt;p&gt;There are a lot of classes of games. They are separated by the mathematical properties of their setting and participants, among other factors.&lt;/p&gt;
&lt;p&gt;There is no global dictionary or atlas for game classes, as interpretations can become nuanced to the extent of opinion. Hence, anytime someone makes a statement in game theory they must specify the class of games it targets. In this article, we will target games that are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Perfect-information.&lt;/strong&gt; Here, all players know everything in the universe that could possibly help them make or avoid any decision, except the decisions that other players will make. Most forms of Poker are not perfect-information, as the exact location of the cards is unknown.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Deterministic.&lt;/strong&gt; Here, if all players choose a strategy and never change it, there is only one possible outcome for the game. Chess is deterministic, because if players make the exact same moves in two different games they are guaranteed to achieve the same result.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sequential.&lt;/strong&gt; More intuitive superset of &lt;a href=&#34;https://cdn.nba.com/headshots/nba/latest/1040x760/2544.png&#34; style=&#34;color: inherit; text-decoration: none&#34;&gt;extensive-form games&lt;/a&gt;. Here, all actions that players can take are indivisible. Soccer is not discrete, because players&amp;rsquo; movements constitute their actions and it is possible to divide any movement into a shorter one.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Extensive-form.&lt;/strong&gt; The adjective &amp;ldquo;extensive-form&amp;rdquo; refers to games that can be written in extensive form, which is a kind of mathematical template. Here, games are defined in terms of the histories of actions that could be observed by the players, and the preferences each player has among them.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;solution-concepts&#34;&gt;Solution concepts&lt;/h4&gt;
&lt;p&gt;There are some questions that are so broadly-applicable in terms of the classes of games they can target that they achieve the special status of a &lt;strong&gt;solution concept.&lt;/strong&gt; This is a term that refers to a characteristic can be observed in a useful set of game classes.&lt;/p&gt;
&lt;p&gt;A very human thing to ask about broad categories of games is who will win. As it turns out, there is no real answer to this question most of the time, because it can come across obstacles like chance, incomplete information, and lack of clarity around the word &amp;ldquo;win.&amp;rdquo; An equally important yet more applicable question, however, is what strategy each player should take to achieve the best possible result for themselves.&lt;/p&gt;
&lt;p&gt;In many cases, it is necessary to tack on additional nuances to this question to be able to answer it. One such refinement of the question (which revolutionized economics) asks which strategy each player should adopt so that no single player could change their own and benefit from it. A pairing of players to strategies is known as a &lt;strong&gt;strategy profile&lt;/strong&gt;, and those that satisfy the above property are known as &lt;strong&gt;Nash Equilibria&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The strategies and strategy profiles that allow players to act probabilistically are called &lt;strong&gt;mixed&lt;/strong&gt;. Mixed strategies are tantamount to sampling &lt;a href=&#34;https://en.wikipedia.org/wiki/Probability_distribution&#34;&gt;probability distributions&lt;/a&gt; of &lt;strong&gt;pure strategies&lt;/strong&gt;, which themselves specify deterministic actions. In 1950, John Nash defined the concept of a Nash Equilibrium (NE), additionally proving that there exists such a mixed strategy profile in all games &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Note&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;Nash Equilibrium is an overloaded term, as it refers to both a solution concept and a strategy profile that satisfies the solution concept. You will need to tell which is which from context.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;computer-science&#34;&gt;Computer science&lt;/h3&gt;
&lt;p&gt;The possibility of players taking actions simultaneously (among other things) can make the existence of a pure-strategy NE impossible. But if sequential play is assumed, it is straightforward to show that there always exists a pure-strategy NE &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. As mentioned above, this article benefits from this assumption.&lt;/p&gt;
&lt;p&gt;Because finding a NE is such a popular desire, most of the discussion here will focus on the procedure of finding a pure-strategy NE in the class of games we specified previously. This is a costly process, which is why it calls for techniques that help minimize use of computational resources. However, you will notice that the things that make this an inherently costly process for some games are actually factors that have nothing to do with game theory.&lt;/p&gt;
&lt;p&gt;Hence, it is possible that the concepts I will discuss are applicable beyond the problem of finding a pure-strategy NE. To elaborate, a maximally generic yet snobby version of this article would perhaps be titled &lt;em&gt;Techniques for Implementing Solutions to Search Problems on Implicit Graphs&lt;/em&gt;. The meanings of these terms are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Implementing.&lt;/strong&gt; Bring into the real world.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Solutions.&lt;/strong&gt; In this context, algorithms that solve problems.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Search Problem.&lt;/strong&gt; A problem that asks you to find something.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Implicit Graph.&lt;/strong&gt; &lt;a href=&#34;https://en.wikipedia.org/wiki/Graph_(abstract_data_type)&#34;&gt;Graph&lt;/a&gt; representation in terms of an initial element and a collection of functions which allow you to perform a traversal. Useful but unconventional term.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In particular, the section titled &amp;ldquo;Representation&amp;rdquo; will explain the link between the definition of an extensive game and the representation of its structure as an implicit graph, and will introduce a trick that can be used to end up with a significantly simpler traversals. This trick is also applicable to problem domains other than games, but I only present it with regard to games because its implementation depends on the underlying problem. Everything else is applicable as soon as you have an implicit graph in your hands.&lt;/p&gt;
&lt;p&gt;While explaining these concepts, it will be useful to have access to ideas in complexity theory. Below are some domain-specific remarks and definitions introducing language that will be of relevance later.&lt;/p&gt;
&lt;h4 id=&#34;complexity-theory&#34;&gt;Complexity theory&lt;/h4&gt;
&lt;p&gt;In computer science, complexity is a measure&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; of the minimal number of elementary operations that must be composed to complete a target operation. The relevant elementary operations correspond to the kind of complexity in question:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Time complexity.&lt;/strong&gt; Here, elementary operations are other operations whose time is assumed to be a known constant. Elementary operations should always be specified.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Space complexity.&lt;/strong&gt; Here, the elementary operation is setting a bit. A more formal definition of space complexity depends on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Model_of_computation&#34;&gt;model of computation&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the sake of expressibility, complexity is usually expressed in terms of &lt;a href=&#34;https://en.wikipedia.org/wiki/Asymptotic_analysis&#34;&gt;asymptotic characteristics&lt;/a&gt;. In particular, symbolisms like &lt;a href=&#34;https://web.mit.edu/16.070/www/lecture/big_o.pdf&#34;&gt;Big-O notation&lt;/a&gt; help compare the asymptotic complexity of different algorithms.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Computational_problem&#34;&gt;Computational problems&lt;/a&gt; can be put into &lt;a href=&#34;https://en.wikipedia.org/wiki/Complexity_class&#34;&gt;complexity classes&lt;/a&gt;. For example, the problem of finding a mixed-strategy NE, known as $\text{N}\small{\text{ASH}}$, is in the time complexity class &lt;a href=&#34;https://en.wikipedia.org/wiki/FNP_(complexity)&#34;&gt;$\text{FNP}$&lt;/a&gt;, which has led many people to look for other solution concepts that are more computationally favorable&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;. The equivalent problem for the class of games we are considering, however, is in &lt;a href=&#34;https://en.wikipedia.org/wiki/FP_(complexity)&#34;&gt;$FP$&lt;/a&gt;. In other words, $\text{N}\small{\text{ASH}}$ can be solved &lt;a href=&#34;https://en.wikipedia.org/wiki/Algorithmic_efficiency&#34;&gt;efficiently&lt;/a&gt; on this restricted domain of games&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;representation&#34;&gt;Representation&lt;/h2&gt;
&lt;p&gt;One can find solutions to instances of many search and decision problems over games without incurring large computational expenses. This is possible by deriving a logical analysis on a case-by-case basis, using the mathematical properties of the components of the game in question.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Definition&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;An &lt;strong&gt;extensive-form game&lt;/strong&gt; is a 4-tuple $\langle N, H, p, (\succsim_i) \rangle$, where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$N$ is a set of players, usually $\{1, \; \ldots, \; n\}$ for simplicity.&lt;/li&gt;
&lt;li&gt;$H$ is a set of strings of actions where $h \in H \implies h&amp;rsquo; \in H$ where $h&amp;rsquo;$ is the string resulting from removing the last action from the string $h$.&lt;/li&gt;
&lt;li&gt;$p : H \to N$ assigns a player to each non-terminal history.&lt;/li&gt;
&lt;li&gt;The player $i \in N$ has a preference relation $\succsim_i$ on the set $Z \subseteq H$ of terminal histories (which is reflexive and transitive).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For a game provided in the extensive form, its instantiation of the above abstractions can be logically leveraged to prove statements about the game. But given that it can be defined arbitrarily, sometimes it is impossible to achieve this solely through formal rewriting.&lt;/p&gt;
&lt;p&gt;In some of these cases it is possible to simply expand the component definitions into their explicit forms in order to later compute a solution using these expansions. But of course, doing this can also be extremely impractical. For example, it is common for $H$ to be of very high cardinality.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;Consider a &lt;a href=&#34;https://en.wikipedia.org/wiki/Rubik%27s_Cube&#34;&gt;Rubik&amp;rsquo;s Cube&lt;/a&gt; that is initialized to specific starting colors, which can be set into the extensive form via the following instantiations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$N = \{1\}$.&lt;/li&gt;
&lt;li&gt;$H = \{ h \; | \; h \text{ is a sequence of 90° rotations of a plane in the cube} \}$.&lt;/li&gt;
&lt;li&gt;$p : h \mapsto 1$ for all $h \in H$.&lt;/li&gt;
&lt;li&gt;$h_i \succsim_1 h_j$ for all $h_i$ that leave the cube solved.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here, the set $H$ is countably infinite, so it is impossible to expand it to its elements in order to later compute a property of this puzzle. One such property is the smallest number of actions that can solve the cube&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;rulesets&#34;&gt;Rulesets&lt;/h3&gt;
&lt;p&gt;Before introducing tools to deal with this, there is another representation that is common when dealing with &lt;a href=&#34;https://en.wikipedia.org/wiki/Abstract_strategy_game&#34;&gt;abstract strategy games&lt;/a&gt;. A ruleset, as it is known in &lt;a href=&#34;https://en.wikipedia.org/wiki/Combinatorial_game_theory&#34;&gt;combinatorial game theory&lt;/a&gt;, is the most familiar kind of representation of a game.&lt;/p&gt;
&lt;p&gt;In particular, a ruleset specifies exactly what actions are permitted to whom and when. It also explains the &lt;a href=&#34;https://en.wikipedia.org/wiki/Utility&#34;&gt;utility&lt;/a&gt; obtained by each participating player when no further actions are available. These characteristics are expressed in terms of the mutable state of a proxy (e.g., a board with pieces).&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;The game &lt;code&gt;10-to-0-by-1-or-2&lt;/code&gt; is generated by the following ruleset:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is a collection of 10 items.&lt;/li&gt;
&lt;li&gt;2 players take alternating turns removing either 1 or 2 items from the collection.&lt;/li&gt;
&lt;li&gt;Player 1 starts. The player who takes the last item from the collection wins.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this game, the collection of items that is mutated by players&amp;rsquo; actions is a proxy that allows players to judge what they are allowed to do and to determine who wins the game.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This way, the information contained in the state of a proxy is a representation of the history of actions that produced it. These representations are called &lt;strong&gt;game states&lt;/strong&gt;. This makes rulesets implicit graphs over the set of game states (denoted $S$). While they do not act directly over a set of histories, rulesets include enough information to generate an equivalent extensive-form representation. The resulting structure of generated action histories is hence intimately tied to the nature of the proxy.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Definition&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;Given a directed graph $G = \langle S, E \rangle$, the corresponding &lt;strong&gt;implicit graph&lt;/strong&gt; $G^I$ is a 3-tuple $\langle S, t, s_0 \rangle$, where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$S$ is a set of states.&lt;/li&gt;
&lt;li&gt;$s_0 \in S$ is a starting element.&lt;/li&gt;
&lt;li&gt;$t : S \to \mathcal{P}(S)$ is a transition dynamics function with $(s_i, s_j) \in E \iff s_j \in t(s_i)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A proof of the bijection between implicit and directed graphs is omitted.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Furthermore, because many actions could be globally or locally commutative with respect to proxies&amp;rsquo; mutable state, sets of histories in the extensive form are usually of much higher cardinality than sets of possible states for rulesets&amp;rsquo; proxies. This is of course computationally favorable, as finite ruelesets (whose proxies have a finite number of possible states) can generate even infinite extensive forms.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;

&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;style&gt;
    .book-column &gt; :first-child:not(.halign-container, .valign-container) {
        margin-top: 0px !important;
    }

    .book-column &gt; :last-child:not(.halign-container, .valign-container) {
        margin-bottom: 0px !important;
    }
&lt;/style&gt;
&lt;div style=&#34;display: flex; flex-wrap: flex&#34;&gt;
       
    &lt;div class=&#34;book-column&#34; style=&#34;flex: 9;&#34;&gt;
        &lt;p&gt;In the diagram to the right, let $S_0$, $S_1$, $S_2$, and $S_3$ be allowed states under a ruleset, and $A = \{a, b\}$ allowed actions. We have that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The set of histories is $H = \{ \epsilon, a, b, ab, ba \}$.&lt;/li&gt;
&lt;li&gt;The set of states is $S = \{ S_0, S_1, S_2, S_3 \}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As you can see, $|H| &amp;gt; |S|$ despite how $|A| &amp;lt; |S|$. The difference in size between $H$ and $S$ scales rapidly in the general case.&lt;/p&gt;

    &lt;/div&gt;
     
    &lt;div class=&#34;book-column&#34; style=&#34;flex: 5;&#34;&gt;
        &lt;style&gt;
    .valign-container {
        display: flex;
        height: 100%;
        align-items: center;  
    }
&lt;/style&gt;
&lt;div class=&#34;valign-container&#34;&gt;
&lt;style&gt;
    .halign-container {
        display: flex;
        width: 100%;
        justify-content: center;  
    }
&lt;/style&gt;
&lt;div class=&#34;halign-container&#34;&gt;
&lt;figure&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;commutative_diagram.png&#34; width=&#34;128&#34;/&gt; 
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;

    &lt;/div&gt;
    
&lt;/div&gt;


&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;abstraction&#34;&gt;Abstraction&lt;/h3&gt;
&lt;p&gt;In real life, games come mostly in the form of rulesets. We are usually aware of the environment they transpire in (the so-called intuitive proxy) and the laws that describe how it can change as a function of players&amp;rsquo; actions. Because of this, much of applied theory is centered around semantics that involve mutable state. For example, a &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_decision_process&#34;&gt;Markov Decision Process (MDP)&lt;/a&gt; from &lt;a href=&#34;https://en.wikipedia.org/wiki/Reinforcement_learning&#34;&gt;reinforcement learning&lt;/a&gt; strongly reflects the nature of a ruleset.&lt;/p&gt;
&lt;p&gt;However, all of these constructs have a latent yet equivalent extensive form representation. This will motivate the technique of &lt;strong&gt;state abstraction&lt;/strong&gt;&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;: The necessity for action histories to be directly prefixed implies that they have a directed tree structure, and because all directed graphs have an equivalent implicit graph representation, the relationship between action histories and ruleset states maps an implicit graph to another one that retains important information about the original.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Definition&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;An &lt;strong&gt;abstraction map&lt;/strong&gt; $a : S_{\text{pre}} \to S_{\text{post}}$ maps the states in an implicit graph $G^I_{\text{pre}}$ to the states in another implicit graph $G^I_{\text{post}}$ with the structure-preserving condition&lt;/p&gt;
$$ s_j \in t_{\text{pre}}(s_i) \iff a(s_j) \in t_{\text{post}}(a(s_i)). $$&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As shown in the last example, the set of action histories is usually of much greater cardinality than its corresponding set of ruleset states, with the difference being possibly infinite. Altogether, this is a hint that, much like the implicit jump from action histories to ruleset states, it is possible to jump to more abstract state sets of smaller cardinality but equal representational power.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;

&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;

&lt;p&gt;An abstraction mapping between the action histories (left) and states (right) from the previous example. Notice how action histories always imply a tree, and the process of abstraction folds it into a potentially cyclic graph.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt; &lt;!-- This is for rendering the above as a &lt;p&gt; element --&gt;&lt;/p&gt;



&lt;style&gt;
    .halign-container {
        display: flex;
        width: 100%;
        justify-content: center;  
    }
&lt;/style&gt;
&lt;div class=&#34;halign-container&#34;&gt;
&lt;figure&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;abstraction.png&#34; width=&#34;475&#34;/&gt; 
&lt;/figure&gt;

&lt;/div&gt;


&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Therefore, much like imposing a ruleset proxy causes many of the action histories to fold into equivalent states, we can determine for a problem $\text{P}$ which states would be $\text{P}$-equivalent under the ruleset&amp;rsquo;s laws. This way, we can create new abstractions $a_i : S_{i - 1} \to S_i$ that can be composed to obtain a reduced state space that is equivalent to the original under $\text{P}$ for a significant computational upside.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;Consider the ruleset underlying the game of Tic-Tac-Toe. Denote $B_i$ a board state. Then, any algorithm that computes a NE for this game through its ruleset is invariant to the abstraction $a$, where&lt;/p&gt;
$$ a(B_i) = a(B_j) \iff B_i \text{ is symmetrical to } B_j. $$&lt;p&gt;Further, the number of board states this algorithm will need to visit is reduced by a factor $&amp;gt;5$.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;design&#34;&gt;Design&lt;/h2&gt;
&lt;p&gt;So far, discussion has brought us to implicit graphs and abstractions through the lens of game theory. The objective of this section will be to motivate these concepts beyond game theory, while supplying references to concrete programming ideas.&lt;/p&gt;
&lt;p&gt;To do this, we will cover a representation of an implicit graph in a real programming language, apply it to a new problem domain, and make improvements that bring real-world utility. Examples will still be given in terms of games, as they also happen to fit under our new focus. In doing so, we will design a solution to a broad problem using our new toolset items.&lt;/p&gt;
&lt;h3 id=&#34;interface-items&#34;&gt;Interface items&lt;/h3&gt;
&lt;p&gt;There are a number of considerations to make when encoding an implicit graph, whose importance will vary depending on the object being represented. This section will introduce only the example of graphs of subproblems in the context of &lt;a href=&#34;https://en.wikipedia.org/wiki/Dynamic_programming&#34;&gt;dynamic programming&lt;/a&gt; (DP), and will iterate on the following &lt;a href=&#34;https://doc.rust-lang.org/book/ch10-02-traits.html&#34;&gt;Rust interface&lt;/a&gt; to eventually allow their solutions to be found in parallel through a special kind of abstraction.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;trait&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImplicitGraph&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;IntoIterator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Item&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;start&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;transition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The elements of this interface declaration relate to the implicit graph $G^I = \langle S, t, s_0 \rangle$ as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The generic parameter &lt;code&gt;Start&lt;/code&gt; is the type of the elements in $S$.&lt;/li&gt;
&lt;li&gt;The generic parameter &lt;code&gt;C&lt;/code&gt; is the type of the elements in $\mathcal{P}(S)$.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;transition&lt;/code&gt; is the template of $t$.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;start&lt;/code&gt; simply returns $s_0$.&lt;/li&gt;
&lt;/ul&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;Implementation of the game &lt;code&gt;10-to-0-by-1-or-2&lt;/code&gt; from the section on Rulesets as an implicit graph.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sd&#34;&gt;/// The game `10-to-0-by-1-or-2`.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sd&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ZeroBy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;impl&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImplicitGraph&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;u32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ZeroBy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// Tuple of (items, turn).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;u32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// Returns (10 items left, player 0&amp;#39;s turn).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;start&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;u32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// Returns states with one and two less items on the opposing player&amp;#39;s turn.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;transition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state&lt;/span&gt;: &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;u32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;u32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;items&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;turn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;next&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;items&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;next&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;turn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;items&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;next&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;items&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;turn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;next&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;items&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;turn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;next&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;parallel-dp&#34;&gt;Parallel DP&lt;/h3&gt;
&lt;p&gt;A popular characterization of DP is to establish dependency &lt;a href=&#34;https://en.wikipedia.org/wiki/Relation_(mathematics)&#34;&gt;relations&lt;/a&gt; on sets of subproblems, defining a &lt;a href=&#34;https://en.wikipedia.org/wiki/Directed_acyclic_graph&#34;&gt;directed acyclic graph&lt;/a&gt; (DAG) for any properly formulated subproblem definition. A natural link to implicit graphs exists through their bijection with general graphs.&lt;/p&gt;
&lt;p&gt;Having established that a DP problem can be characterized as an implicit graph of subproblems, it is also worth mentioning that most unorganized solution implementations (i.e., that do not organize solutions or information about subproblems in a tensor) make use of stack-like data structures to aid traversals of subproblems in &lt;a href=&#34;https://en.wikipedia.org/wiki/Tree_traversal&#34;&gt;postorder&lt;/a&gt;.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;DP algorithm to compute who will win a game of &lt;code&gt;10-to-0-by-1-or-2&lt;/code&gt;, with the below subproblem relation&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
$$ W(s) = \max_{s&#39; \in \\, t(s)} \min_{s&#39; \in \\, t(s)} W(s&#39;). $$&lt;p&gt;Here, $W : S \to \{ 0, \, 1 \} $ maps state information (including the number of items remaining and player turn) to whether the player whose turn it is at $s$ would win under optimal play, with $t$ being the transition function of the implicit graph over this game&amp;rsquo;s states. This uses the implementation from the previous example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;procedure:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  temp ← empty stack
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  stack ← empty stack
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  visited ← empty set
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  stack.push(ZeroBy::start())
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  while stack is not empty:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    current ← stack.pop()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    if current is not in visited:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      visited.add(current)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      temp_stack.push(current)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      for each state in ZeroBy::transition(current):
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        if state is not in visited:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          stack.push(state)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  solution ← empty map
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  while temp_stack is not empty:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    current ← temp_stack.pop()
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    solution[current] = W(current)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  return solution[ZeroBy::start()]&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Note the use of $W$ in line 19. Also note that the subproblem relation does not necessarily generalize to other games and, for the sake of brevity, is not defined for base cases (where $t(s) = \varnothing$).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Attempts to parallelize this setup must first identify a method to partition the subproblem graph in a way optimizes the tradeoff between parallelism and its own overhead. Of course, this depends significantly on the specific resources that will be used to execute the resulting program.&lt;/p&gt;
&lt;p&gt;I will introduce one way of doing this that follows naturally from the use of the implicit graph interface. Concretely, a carefully chosen abstraction $\pi : S \to \mathbb{N}$ that connects the graph of subproblems to a DAG of enumerated sets of states will provide a parallelization scheme.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;trait&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImplicitGraph&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;IntoIterator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Item&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;start&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;partition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;kt&#34;&gt;u64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// &amp;lt;-- NEW
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;transition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here, &lt;code&gt;partition&lt;/code&gt; is the template of $\pi$. The big idea is that during a traversal, we can observe a change in the value of &lt;code&gt;*::partition(current)&lt;/code&gt;, where &lt;code&gt;current&lt;/code&gt; is the current state in the traversal. This way, we can build a graph of the outputs of this function based on their adjacency in the subproblem graph. Finally, we analyze the resulting graph to find sets of states that can be traversed simultaneously.&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Example&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;p&gt;On the left, a graph over a set of states $S = \{ s_0, \, \ldots, \, s_{11} \}$. On the right, a graph over a set $\Pi \subset \mathbb{N}$ with four elements. They are related by an abstraction $\pi : S \to \Pi$ that is special in that the resulting graph over the elements of $\Pi$ is acyclic. Hence, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Fiber_(mathematics)&#34;&gt;fibers&lt;/a&gt; $\pi^{-1}(\{\pi_i\})$ of certain distinct elements $(\pi_i)$ of $\Pi$ could possibly be traversed in parallel. An example of groupings of elements in  $\Pi$ whose fibers under $\pi$ could be traversed in parallel is provided in dotted boxes on the graph of $\Pi$.&lt;/p&gt;
&lt;figure&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;partition.png&#34; width=&#34;550&#34;/&gt; 
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Finding a suitable $\pi$ depends on the chosen state (subproblem) representation and is of course highly problem-specific. However, a general strategy is to ensure that $\pi$ outputs a different label if and only if an irreversible change is made to some form of mutable state. As a high-level criterion, this helps construct an abstraction that assuredly maps onto a DAG.&lt;/p&gt;
&lt;p&gt;Having found such an abstraction, the next perplexity of parallelizing a postorder traversal of subproblems is managing efficient and clear use of shared data structures. Here, a zoo of approaches with varyingly personable tradeoffs are available. I will introduce only one, which involves an additional interface item in the form of a function $t&amp;rsquo; : S \to \mathcal{P}(S)$ called &lt;code&gt;retrograde&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;trait&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImplicitGraph&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;IntoIterator&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Item&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;start&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;partition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;kt&#34;&gt;u64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;transition&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;retrograde&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;state&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;State&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// &amp;lt;-- NEW
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In an ideal world, &lt;code&gt;retrograde&lt;/code&gt; is the equivalent of &lt;code&gt;transition&lt;/code&gt; for the &lt;a href=&#34;https://en.wikipedia.org/wiki/Transpose_graph&#34;&gt;transpose&lt;/a&gt; of the graph being represented. Unfortunately, it is not generally tractable to have a perfect implementation of &lt;code&gt;retrograde&lt;/code&gt; without first materializing the entire graph (defeating the purpose of an implicit graph representation). Thus, we only make sure that &lt;code&gt;retrograde&lt;/code&gt; returns a superset of what &lt;code&gt;transition&lt;/code&gt; would return for the transpose of the graph, which is easy to ensure in many useful cases.&lt;/p&gt;
&lt;p&gt;With $\pi$ and $t&amp;rsquo;$ in our hands, we can provision the following procedure for parallelizing the execution of an unorganized dynamic programming algorithm over an implicit graph $G^I$ of subproblems:&lt;/p&gt;
&lt;style&gt;
    .box-body &gt; :last-child {
        margin-bottom: 0 !important;
    }

    .box-body &gt; :first-child {
        margin-top: 0 !important;
    }
&lt;/style&gt;
&lt;div
    class=&#34;hint-box&#34;
    style=&#34;
        border: 1px solid #000000;
        padding: 10px;
        border-radius: 5px;
        margin: 25px 0;
        background-color: rgba(0, 0, 0, 0.05);
    &#34;
&gt;
    &lt;strong style=&#34;display: block; margin-bottom: 5px&#34;
        &gt;Procedure&lt;/strong
    &gt;
    &lt;hr
        style=&#34;
            border: none;
            border-top: 1px solid #000000;
            margin: 10px 0;
            width: calc(100%);
        &#34;
    /&gt;
    &lt;div style=&#34;font-size: 0.92em&#34; class=&#34;box-body&#34;&gt;
&lt;ol&gt;
&lt;li&gt;Traverse $G^I$ to obtain the set of subproblems $S$ in $\mathcal{\Theta}(|G^I|)$ time and $\mathcal{\Theta}(|S|)$ space.&lt;/li&gt;
&lt;li&gt;During (1), track the subset of subproblems $S_{base} = \{ s \; | \; t(s) = \varnothing \}$ at no additional cost.&lt;/li&gt;
&lt;li&gt;During (1), construct a graph $G_\Pi$ over a set of partition labels $\Pi$ using $\pi$, at a $\pi$-dependent cost.&lt;/li&gt;
&lt;li&gt;Use $G_\Pi$ to generate a plan&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt; of labeled parallel tasks in $\mathcal{\Theta}(|G_\Pi|)$ time and $\mathcal{\Theta}(|\Pi|)$ space.&lt;/li&gt;
&lt;li&gt;Delegate tasks, starting exploration from popped elements of $S_{base}$ with the task&amp;rsquo;s label.&lt;/li&gt;
&lt;li&gt;Use $t&amp;rsquo;$ for backward intra-partition traversal (using $S$ for existence checks) in $t&amp;rsquo;$-dependent time.&lt;/li&gt;
&lt;li&gt;When a change in $\pi(s)$ is observed on the current state $s$, add $s$ to $S_{base}$, leaving it unexplored.&lt;/li&gt;
&lt;li&gt;When a partition is completely explored, finish its task and free the parallel unit.&lt;/li&gt;
&lt;li&gt;Repeat from (5) on new elements of $S_{base}$ until there are no tasks remaining.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;These general steps skip some details, but they present an arbitrarily parallel stack-free traversal that can be implemented over a single shared data structure whose size scales in the order of $\mathcal{\Theta}(|S|)$ (ignoring structures related to partitions, whose size is assumed to be negligible). This kind of map-like &lt;a href=&#34;https://en.wikipedia.org/wiki/Thread_safety&#34;&gt;thread-safe&lt;/a&gt; functionality is available in many database implementations which automatically bring the added benefit of disk usage, making this method applicable to &amp;ldquo;bigger&amp;rdquo; problems.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;meta-content&#34;&gt;Meta-content&lt;/h2&gt;
&lt;p&gt;The section titled &amp;ldquo;Representation&amp;rdquo; got us to stumble across the new concepts of implicit graphs and abstractions by looking at different forms for game representations. The following section extrapolated these ideas to the domain of dynamic programming, and showed how it is possible to incorporate them into the design of solutions to real-world problems.&lt;/p&gt;
&lt;p&gt;Something interesting is that games made their way into the second section, despite being decidedly out of scope at that point. In a dying hope of getting this article back on track, I will point out that the particular example of parallelizing DP algorithms was conveniently chosen because it is used to &lt;a href=&#34;https://en.wikipedia.org/wiki/Solved_game&#34;&gt;solve&lt;/a&gt; bigger games faster than was previously possible (through DP algorithms that consume representations of them).&lt;/p&gt;
&lt;p&gt;This way, I can say that this whole article was in fact about game-theoretic systems. But we both know that it was really about implicit graphs and abstractions. Maybe, if we squint our eyes, it can be about both topics. Either way, I hope the lack of clarity was more stimulating than it was confusing.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;The problem of deciding whether or not a string is in the language of a context-free grammar.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;For his doctoral dissertation, &lt;a href=&#34;https://gametheory.online/projects/documents/1521541344.pdf&#34;&gt;&lt;em&gt;Non-Cooperative Games&lt;/em&gt;&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;This fact is known as &lt;a href=&#34;https://en.wikipedia.org/wiki/Zermelo%27s_theorem_(game_theory)&#34;&gt;Zermelo&amp;rsquo;s theorem&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;In both &lt;a href=&#34;https://en.wikipedia.org/wiki/Measure_(mathematics)&#34;&gt;the mathematical&lt;/a&gt; and informal sense.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;For example, &lt;a href=&#34;https://www.youtube.com/watch?v=-aSBlRhpwVc&#34;&gt;Christos Papadimitrou on replicator dynamics&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;$\text{N}\small{\text{ASH}}$ asks to find a mixed-strategy NE. A pure-strategy NE is a case of a mixed-strategy NE. &lt;a href=&#34;https://en.wikipedia.org/wiki/Zermelo%27s_theorem_(game_theory)&#34;&gt;Zermelo&amp;rsquo;s theorem&lt;/a&gt; shows a pure-strategy NE always exists for the class of games in question. Then, &lt;a href=&#34;https://en.wikipedia.org/wiki/Backward_induction&#34;&gt;backward induction&lt;/a&gt; algorithms can find one in linear time for finite representations of games.&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;
&lt;p&gt;It is possible to obtain this number for a specific starting configuration of a Rubik&amp;rsquo;s Cube, but no one knows the length of the longest minimal sequence of moves necessary to solve it across all starting configurations. This is somewhat dramatically known as &lt;a href=&#34;https://web.archive.org/web/20141109174500/http://digitaleditions.walsworthprintgroup.com/article/The_Quest_For_God%E2%80%99s_Number/532775/50242/article.html&#34;&gt;God&amp;rsquo;s Number&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34;&gt;
&lt;p&gt;Term generalized from &lt;a href=&#34;https://www2.eecs.berkeley.edu/Pubs/TechRpts/2001/CSD-01-1156.pdf&#34;&gt;its use in reinforcement learning&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34;&gt;
&lt;p&gt;This subproblem relation monomorphizes the generic formulation of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Minimax&#34;&gt;minimax algorithm&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34;&gt;
&lt;p&gt;A parallelization plan is a data structure that can dispense information on which task must be worked on next when a parallel unit becomes available for work. It may also communicate the need to wait until another unit completes its work.&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    
  </channel>
</rss>
