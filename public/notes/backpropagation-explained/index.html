<!DOCTYPE html>
<html lang="en"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
    <meta name="description" content="Max&#39;s personal site">
    
     
    <link rel="icon" type="image/x-icon" href="/favicon.ico" media="(prefers-color-scheme: light)">
    <link rel="icon" type="image/x-icon" href="/favicon-dark.ico" media="(prefers-color-scheme: dark)"> 
     
    

    

    
    <link rel="stylesheet" href="/css/style.min.css">

    <link rel="canonical" href="http://localhost:1313/notes/backpropagation-explained/" />
    <title>Backpropagation Explained</title>
</head>
<body><header id="banner">
    <h2><a href="/">Max Fierro</a></h2>
    <nav>
        <ul>
            <li>
                <a href="/resume/" title=""
                    >resume</a
                >
            </li><li>
                <a href="/music/" title=""
                    >music</a
                >
            </li><li>
                <a href="/notes/" title=""
                    >notes</a
                >
            </li><li>
                <a href="/index.xml" title=""
                    >rss</a
                >
            </li>
        </ul>
    </nav>
</header>
<main id="content">
<article>
    <header id="post-header">
        <h1>Backpropagation Explained</h1><div>
            Part of the Machine Learning Basics series.
        </div></header><p>Backpropagation is the fundamental algorithm that allows neural networks to learn from data. It works by computing gradients of the loss function with respect to each weight in the network.</p>
<h2 id="the-algorithm">The Algorithm</h2>
<ol>
<li><strong>Forward Pass</strong>: Input data flows through the network to produce predictions</li>
<li><strong>Compute Loss</strong>: Calculate the error between predictions and actual values</li>
<li><strong>Backward Pass</strong>: Propagate the error backward through the network</li>
<li><strong>Update Weights</strong>: Adjust weights using gradient descent</li>
</ol>
<p>This process repeats until the network achieves satisfactory performance.</p>
<nav class="series-navigation">
                <div class="series-nav-links" style="display: flex; justify-content: space-between;"><a href="/notes/introduction-to-neural-networks/" class="prev-note">‹ Introduction to Neural Networks</a></div>
            </nav></article>

        </main><footer id="footer">
    Copyright © 2024 Max Fierro
</footer>
</body>
</html>
