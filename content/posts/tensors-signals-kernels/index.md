---
title: "Perspectives into Tensors, Signals, and Kernel Methods"
category: technical
date: 2025-09-08
math: true
draft: true
---

{{< toc >}}

## Abstract

[Linear algebra](https://linear.axler.net/LADR4e.pdf), [signal processing](https://en.wikipedia.org/wiki/Signal_processing), and [machine learning](https://en.wikipedia.org/wiki/Machine_learning) are (one of many groups of) topics that enjoy a beautiful relationship protected by a nutshell of mathematics. Inside we can find a kernel of perspectives which are simply a pleasure to entertain. Here, I provide the [linear-operator](https://en.wikipedia.org/wiki/Linear_map) perspective into [systems of many dimensions](https://en.wikipedia.org/wiki/Multidimensional_system), characterizing properties like [time-invariance](https://en.wikipedia.org/wiki/Time-invariant_system) and [causality](https://en.wikipedia.org/wiki/Causal_system) via [tensor](https://en.wikipedia.org/wiki/Tensor) representations. I finish with an original perspective that connects the [convolution kernel](https://en.wikipedia.org/wiki/Convolution) to the [reproducing kernel](https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space#:~:text=then%20called%20the-,reproducing%20kernel,-%2C%20and%20it%20reproduces).

---

## Background 

This section is no more than a refresher on select topics. I will not make an attempt to explain them completely. If this is what you need, I recommend you explore these (completely free) resources:

1. **Vector spaces.** [_Linear Algebra Done Right_](https://linear.axler.net/) by Axler.
2. **Signals and Systems.** [_Signals & Systems: Theory and Applications_](https://ss2-2e.eecs.umich.edu/) by Ulaby and
Yagle.
3. **Kernel methods.** [_Foundations of Machine Learning_](https://cs.nyu.edu/~mohri/mlbook/) by Mohri, Rostamizadeh, and Talwalkar.

### Vector Spaces 



### Signals and Systems 

### Kernel Methods

---


